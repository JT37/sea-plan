### Redis 数据不一致问题
![redis缓存删除与入库先后问题](../../Picture/redis缓存删除与入库先后问题.jpeg)

#### 如何解决数据不一致问题？

重试机制。

具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 `Kafka` 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。

如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

![Redis缓存删除失败重试机制](../../Picture/Redis缓存删除失败重试机制.jpeg)

#### 缓存不一致两个解决方案

- 删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。

- 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。

![Redis只读缓存数据不一致情况](../../Picture/Redis只读缓存数据不一致情况.jpeg)


针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：

- 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；
- 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。


不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 `Redis` 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。


### 缓存雪崩、击穿、穿透

#### 缓存雪崩

缓存雪崩是指大量的应用请求无法在 `Redis` 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。

##### 缓存雪崩一般是由两个原因导致
第一个原因：缓存中有大量数据同时过期，导致大量请求无法得到处理，应用就会把请求发送给数据库，从数据库中读取数据，造成数据库压力增大，影响其它正常业务处理。
![Redis缓存雪崩](../../Picture/Redis缓存雪崩.webp)

针对大量数据同时失效带来的缓存雪崩问题，提供两种解决方案。

- 避免给大量的数据设置相同的过期时间，给这些数据的过期时间增加一个较小的随机数。
- 服务降级，指发生缓存雪崩时，针对不同的数据采取不同的处理方式。
  - 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；
  - 当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

第二个原因：`Redis` 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。

针对 `Redis` 实例宕机的缓存雪崩问题，提供两种建议。

- 第一个建议，在业务系统中实现服务熔断或请求限流机制。
  - 所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给 `Redis` 缓存实例，而是直接返回，等到 `Redis` 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。避免了大量请求因缓存缺失，而积压到数据库系统，保证了数据库系统的正常运行。

  - 服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流。这里说的请求限流，就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。

  - 使用服务熔断或是请求限流机制，是在雪崩后，来降低雪崩对数据库和整个业务系统的影响。

- 第二个建议，事前预防。
  - 通过主从节点的方式构建 `Redis` 缓存高可靠集群。如果 `Redis` 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。

#### 缓存击穿

缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。

为了避免缓存击穿给数据库带来的激增压力，解决方法也比较直接，对于访问特别频繁的热点数据，就不设置过期时间了。

![Redis缓存击穿](../../Picture/Redis缓存击穿.webp)


#### 缓存穿透

缓存穿透是指要访问的数据既不在 `Redis` 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。

![Redis缓存穿透](../../Picture/Redis缓存穿透.webp)

##### 缓存穿透发生的两种情况
- 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；
- 恶意攻击：专门访问数据库中没有的数据。

##### 缓存穿透三种应对方案

第一种方案是，缓存空值或缺省值。业务从 `Redis` 读取空值或缺省值，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。

第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。

第三种方案，在请求入口的前端进行请求检测。一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。


#### 三种异常汇总
![Redis三种异常情况](../../Picture/Redis三种异常情况.webp)

针对异常情况，三种预防式方案：
- 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；
- 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；
- 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。


### 缓存污染

在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

#### LRU 缓存策略

`LRU` 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。

`Redis` 中的 `LRU` 策略，会在每个数据对应的 `RedisObject` 结构体中设置一个 `lru` 字段，用来记录数据的访问时间戳。在进行数据淘汰时，`LRU` 策略会在候选数据集中淘汰掉 `lru` 字段值最小的数据（也就是访问时间最久的数据）。

在数据被频繁访问的业务场景中，`LRU` 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。

正是因为只看数据的访问时间，使用 `LRU` 策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 `lru` 字段值都很大。而频繁查询的热点数据由于 `lru` 字段值相对小，被置换出去了，把这些偶发性数据留下了，从而导致LRU的数据命中率急剧下降。

对于周期性、偶发性的访问数据，有大概率可能造成缓存污染，

例如：当一个新剧热播，流量涌入，此剧的相关缓存登顶。但当新剧热度降低趋势变得平缓，其他周期性播出的综艺类节目涌入后将新剧缓存挤出， 这是我又访问新剧，则不得不又将新剧加入缓存，这显然不合时宜，因为新剧我已经访问过很多次了。

![Redis使用LRU的缓存污染](../../Picture/Redis使用LRU的缓存污染.webp)

所以，对于采用了 `LRU` 策略的 `Redis` 缓存来说，扫描式单次查询会造成缓存污染。为了应对这类缓存污染问题，`Redis` 从 `4.0` 版本开始增加了 `LFU` 淘汰策略。

与 `LRU` 策略相比，`LFU` 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

#### LFU 缓存策略的优化

`LFU` 缓存策略是在 `LRU` 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 `LFU` 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，`LFU` 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，`LFU` 策略会优先把这些访问次数低的数据淘汰出缓存。

##### LFU 实现
`Redis` 在实现 `LFU` 策略的时候，只是把原来 `24bit` 大小的 `lru` 字段，又进一步拆分成了两部分。
- `ldt` 值：`lru` 字段的前 `16bit`，表示数据的访问时间戳；
- `counter` 值：`lru` 字段的后 `8bit`，表示数据的访问次数。

总结一下：当 `LFU` 策略筛选数据时，`Redis` 会在候选集合中，根据数据 `lru` 字段的后 `8bit` 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 `lru` 字段的前 `16bit` 值大小，选择访问时间最久远的数据进行淘汰。

`Redis` 只使用了 `8bit` 记录数据的访问次数，而 `8bit` 记录的最大值是 `255`。所以，`Redis` 在实现 `LFU` 策略时，`Redis` 并没有采用数据每被访问一次，就给对应的 `counter` 值加 `1` 的计数规则，而是采用了一个更优化的计数规则。

##### LFU 策略计数器实现

简单来说，`LFU` 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 `lfu_log_factor` 再加 `1`，再取其倒数，得到一个 `p` 值；然后，把这个 `p` 值和一个取值范围在 `（0，1）` 间的随机数 `r` 值比大小，只有 `p` 值大于 `r` 值时，计数器才加 `1`。

![Redis的LFU策略计数器递增的效果](../../Picture/Redis的LFU策略计数器递增的效果.webp)

当 `lfu_log_factor` 取值为 `1` 时，实际访问次数为 `100K` `后，counter` 值就达到 `255` 了，无法再区分实际访问次数更多的数据了。而当 `lfu_log_factor` 取值为 `100` 时，当实际访问次数为 `10M` `时，counter` 值才达到 `255`，此时，实际访问次数小于 `10M` 的不同数据都可以通过 `counter` 值区分出来。

正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，`LFU` 策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。在应用 `LFU` 策略时，一般可以将 `lfu_log_factor` 取值为 `10`。

##### LFU 针对 counter 值的衰减机制

应用负载的情况是很复杂的。在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。`Redis` 在实现 `LFU` 策略时，设计了一个 `counter` 值的衰减机制。

简单来说，`LFU` 策略使用衰减因子配置项 `lfu_decay_time` 来控制访问次数的衰减。`LFU` 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，`LFU` 策略再把这个差值除以 `lfu_decay_time` 值，所得的结果就是数据 `counter` 要衰减的值。

假设 `lfu_decay_time` 取值为 `1`，如果数据在 `N` 分钟内没有被访问，那么它的访问次数就要减 `N`。如果 `lfu_decay_time` 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。

在实际业务应用中，`LRU` 和 `LFU` 两个策略都有应用。`LRU` 和 `LFU` 两个策略关注的数据访问特征各有侧重，`LRU` 策略更加关注数据的时效性，而 `LFU` 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 `LRU` 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，`LFU` 策略就可以很好地应对缓存污染问题了，建议优先使用。