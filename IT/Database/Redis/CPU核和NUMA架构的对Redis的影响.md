### 主流的 CPU 架构

一个 `CPU` 处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有**私有**的一级缓存（`Level 1 cache`，简称 `L1 cache`），包括一级指令缓存和一级数据缓存，以及**私有**的二级缓存（`Level 2 cache`，简称 `L2 cache`）。

物理核的私有缓存：其实是指缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取。

CPU物理核的架构
![CPU物理核的架构](../../Picture/CPU物理核的架构.jpeg)

因为 `L1` 和 `L2` 缓存是每个物理核私有的，所以，当数据或指令保存在 `L1`、`L2` 缓存时，物理核访问它们的延迟不超过 `10` 纳秒，速度非常快。

但是，这些 `L1` 和 `L2` 缓存的大小受限于处理器的制造技术，一般只有 `KB` 级别，存不下太多的数据。如果 `L1`、`L2` 缓存中没有所需的数据，应用程序就需要访问内存来获取数据。而应用程序的访存延迟一般在百纳秒级别，是访问 `L1`、`L2` 缓存的延迟的近 `10` 倍，不可避免地会对性能造成影响。

所以，不同的物理核还会共享一个共同的三级缓存（`Level 3 cache`，简称为 `L3 cache`）。`L3` 缓存能够使用的存储资源比较多，所以一般比较大，能达到 `几 MB 到几十 MB`，这就能让应用程序缓存更多的数据。当 `L1`、`L2` 缓存中没有数据缓存时，可以访问 `L3`，**尽可能避免访问内存**。

现在主流的 `CPU` 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 `L1`、`L2` 缓存。

`CPU`物理核和逻辑核及一二级缓存
![CPU物理核和逻辑核及一二级缓存](../../Picture/CPU物理核和逻辑核及一二级缓存.jpeg)


在主流的服务器上，一个 `CPU` 处理器会有 `10` 到 `20` 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 `CPU` 处理器（也称为`多 CPU Socket`），每个处理器有自己的物理核（包括 `L1`、`L2` 缓存），`L3` 缓存，以及连接的内存，同时，不同处理器间通过总线连接。

多 `CPU Socket` 的架构
![多CPUSocket的架构](../../Picture/多CPUSocket的架构.jpeg)

在多 `CPU` 架构上，应用程序可以在不同的处理器上运行。在上图中，`Redis` 可以先在 `Socket 1` 上运行一段时间，然后再被调度到 `Socket 2` 上运行。

如果应用程序先在一个 `Socket` 上运行，并且把数据保存到了内存，然后被调度到另一个 `Socket` 上运行，此时，应用程序再进行内存访问时，就需要访问之前 `Socket` 上连接的内存，这种访问属于远端内存访问。和访问 `Socket` 直接连接的内存相比，远端内存访问会增加应用程序的延迟。

在多 `CPU` 架构下，一个应用程序访问所在 `Socket` 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（`Non-Uniform Memory Access，NUMA 架构`）。

`CPU` 架构对应用程序运行的影响
- `L1`、`L2` 缓存中的指令和数据的访问速度很快，所以，充分利用 `L1`、`L2` 缓存，可以有效缩短应用程序的执行时间；
- 在 `NUMA` 架构下，如果应用程序从一个 `Socket` 上调度到另一个 `Socket` 上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间。

### CPU 多核对 Redis 性能的影响

在一个 `CPU` 核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、`CPU` 核的寄存器值等），我们把这些信息称为运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到 `L1`、`L2` 缓存上，以便提升执行速度。

在多核 `CPU` 的场景下，一旦应用程序需要在一个新的 `CPU` 核上运行，那么，运行时信息就需要重新加载到新的 `CPU` 核上。而且，新的 `CPU` 核的 `L1`、`L2` 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。

尾延迟：`99%` 的请求延迟小于的值就是 `99%` 尾延迟。
