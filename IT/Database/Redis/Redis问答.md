#### 1. 和跟 Redis 相比，SimpleKV 还缺少什么？
![SimpleKV和Redis对比](../../Picture/SimpleKV和Redis对比.jpeg)

#### 2. Memcached 相比 Redis 唯一还能算优势的地方
- 支持多线程，可扩展
- 可通过增加 `CPU` 数量，提升 `Memcached` 性能
- 在 `key` 的 `value` 较大的场景中，性能优势较明显。

#### 3. Redis 为什么快？
- 内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快
- 数据结构，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 `Redis` 快速处理数据的基础
- 采用了多路复用机制，使其在网络 `IO` 操作中能并发处理大量的客户端请求，实现高吞吐率


#### 4. 整数数组和压缩列表作为底层数据结构的优势是什么？

整数数组和压缩列表的设计，充分体现了 `Redis` “又快又省”特点中的“省”，也就是节省内存空间。整数数组和压缩列表都是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。因为元素是挨个连续放置的，我们不用再通过额外的指针把元素串接起来，这就避免了额外指针带来的空间开销

![整数数组和压缩列表的数据结构](../../Picture/整数数组和压缩列表的数据结构.jpeg)

`Redis` 之所以采用不同的数据结构，其实是在性能和内存使用效率之间进行的平衡。


#### 5. Redis 基本 IO 模型中除了使用多路复用机制外还有哪些潜在的性能瓶颈？

在 `Redis` 基本 `IO` 模型中，主要是主线程在执行操作，任何耗时的操作，例如 `bigkey`、全量返回等操作，都是潜在的性能瓶颈。

#### 6. AOF 重写过程中有没有其他潜在的阻塞风险？

风险一：`Redis` 主线程 `fork` 创建 `bgrewriteaof` 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（`Process Control Block，简称为 PCB`）。内核要把主线程的 `PCB` 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 `Redis` 实例的内存大小有关。如果 `Redis` 实例内存大，页表就会大，`fork` 执行时间就会长，这就会给主线程带来阻塞风险。

风险二：`bgrewriteaof` 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 `bigkey`，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。

#### 7. AOF 重写为什么不共享使用 AOF 本身的日志？

如果都用 `AOF` 日志的话，主线程要写，`bgrewriteaof` 子进程也要写，这两者会竞争文件系统的锁，这就会对 `Redis` 主线程的性能造成影响。

#### 8. 为什么主从库间的复制不使用 AOF？
- `RDB` 文件是二进制文件，无论是要把 `RDB` 写入磁盘，还是要通过网络传输 `RDB`，`IO` 效率都比记录和传输 `AOF` 的高。
- 在从库端进行恢复时，用 `RDB` 的恢复效率要高于用 `AOF`

#### 9. 具体场景下，用 RDB 做持久化有什么风险吗？
 场景： 使用一个 `2 核 CPU`、`4GB` 内存、`500GB` 磁盘的云主机运行 `Redis`，`Redis` 数据库的数据量大小差不多是 `2GB`。当时 `Redis` 主要以修改操作为主，写读比例差不多在 `8:2` 左右，也就是说，如果有 `100` 个请求，`80` 个请求执行的是修改操作。

 ##### 内存不足的风险
 `Redis` `fork` 一个 `bgsave` 子进程进行 `RDB` 写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为 `80%`，那么，在持久化过程中，为了保存 `80%` 写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的 `80%`，大约是 `1.6GB`，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新 `key` 写入或 `key` 修改，云主机内存很快就会被吃光。如果云主机开启了 `Swap` 机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启 `Swap`，会直接触发 `OOM(Out Of Memory)`，整个 `Redis` 实例会面临被系统 `kill` 掉的风险。

 #### 主线程和子进程竞争使用 CPU 的风险
生成 `RDB` 的子进程需要 `CPU` 核运行，主线程本身也需要 `CPU` 核运行，而且，如果 `Redis` 还启用了后台线程，此时，主线程、子进程和后台线程都会竞争 `CPU` 资源。由于云主机只有` 2 核 CPU`，这就会影响到主线程处理请求的速度。


### 10. 在主从切换过程中，客户端能否正常地进行请求操作呢?
主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。

### 11. 如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？
一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（`Redis` 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。

另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。

### 12. 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？

因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于 `quorum` 值，现在还剩 `2` 个哨兵实例，个数正好等于 `quorum` 值，所以还能正常判断主库是否处于“客观下线”状态。如果一个哨兵想要执行主从切换，就要获到半数以上的哨兵投票赞成，也就是至少需要 `3` 个哨兵投票赞成。但是，现在只有 `2` 个哨兵了，所以就无法进行主从切换了。

### 13. 哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？

哨兵实例越多，误判率会越低，但是在判定主库下线和选举 `Leader` 时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对 `Redis` 的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。调大 `down-after-milliseconds` 后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到 `Redis` 对业务的可用性。

调大 `down-after-milliseconds` 后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到 Redis 对业务的可用性。